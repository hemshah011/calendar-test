{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import brentq\n",
    "from datetime import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global Variables\n",
    "\n",
    "risk_free_rate=0.05\n",
    "timeframe= '30min'\n",
    "trading_sessions= 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Math Logic\n",
    "\n",
    "# Black-Scholes formula\n",
    "def black_scholes_price(S, K, T, r, sigma, option_type=\"C\"):\n",
    "    d1 = (np.log(S / K) + (r + 0.5 * sigma ** 2) * T) / (sigma * np.sqrt(T))\n",
    "    d2 = d1 - sigma * np.sqrt(T)\n",
    "\n",
    "    if option_type == \"C\":\n",
    "        return S * norm.cdf(d1) - K * np.exp(-r * T) * norm.cdf(d2)\n",
    "    elif option_type == \"P\":\n",
    "        return K * np.exp(-r * T) * norm.cdf(-d2) - S * norm.cdf(-d1)\n",
    "\n",
    "# Implied Volatility using Newton Raphson\n",
    "def calculate_iv(option_price, S, K, T, r, option_type=\"C\"):\n",
    "    def bs_error(sigma):\n",
    "        return black_scholes_price(S, K, T, r, sigma, option_type) - option_price\n",
    "\n",
    "    try:\n",
    "        return brentq(bs_error, 1e-6, 3)  \n",
    "    except ValueError:\n",
    "        return np.nan  \n",
    "\n",
    "#Find z-score for mean reversion\n",
    "def calculate_zscore(data, lookback):\n",
    "    mean = data.rolling(window=lookback).mean()\n",
    "    std = data.rolling(window=lookback).std()\n",
    "    zscore = (data - mean) / std\n",
    "    return zscore\n",
    "\n",
    "#Calculates sharpe for a pnl series\n",
    "def calculate_sharpe_ratio(returns, risk_free_rate=0):\n",
    "    excess_returns = returns - risk_free_rate\n",
    "    sharpe_ratio= excess_returns.mean() / excess_returns.std()\n",
    "    return sharpe_ratio\n",
    "\n",
    "#Max drawdown of a pnl series\n",
    "def calculate_drawdown(returns):\n",
    "  cumulative_returns = (1 + returns).cumprod()\n",
    "  peak = cumulative_returns.cummax()\n",
    "  drawdown = (cumulative_returns - peak) / peak\n",
    "  return drawdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data operations\n",
    "\n",
    "#Load Data\n",
    "def load_data(file_path):\n",
    "    data = pd.read_csv(file_path, parse_dates=['start_ts'], usecols=['symbol','start_ts','open','high','low','close','volume','vwap'])\n",
    "    data = data.dropna()\n",
    "    return data\n",
    "\n",
    "def strip_extra_trading_hours(data):\n",
    "    \n",
    "    data=data.reset_index()\n",
    "\n",
    "    data = data.drop(data[data['start_ts'].dt.time< time(9,30,0)].index)\n",
    "    data = data.drop(data[data['start_ts'].dt.time>= time(16,0,0)].index)\n",
    "\n",
    "    return data\n",
    "\n",
    "'''Filter the Data\n",
    "    1. Convert to 30min timeframe\n",
    "    2. Strip off extra trading hours\n",
    "'''\n",
    "def convert_eqt_data(eqt,new_timeframe):  \n",
    "\n",
    "    eqt = eqt.set_index('start_ts')\n",
    "\n",
    "    eqt_data = eqt.resample(new_timeframe).agg(    \n",
    "        close= ('close', 'last'),\n",
    "        Weighed_Price_Volume= ('vwap', lambda x:(x* eqt.loc[x.index, 'volume']).sum()),\n",
    "        volume= ('volume','sum'),\n",
    "        symbol= ('symbol','last')\n",
    "    )\n",
    "\n",
    "    eqt_data['vwap'] = eqt_data['Weighed_Price_Volume']/eqt_data['volume']\n",
    "    eqt_data=eqt_data.drop(columns=['Weighed_Price_Volume'])\n",
    "\n",
    "    #Strip off extra trading hours\n",
    "    eqt_data=strip_extra_trading_hours(eqt_data)\n",
    "\n",
    "    eqt_data= eqt_data.reset_index()\n",
    "    eqt_data = eqt_data.dropna()\n",
    "    return eqt_data\n",
    "\n",
    "#See the data is alredy sorted\n",
    "def data_filtering(option):\n",
    "\n",
    "    #Add columns \n",
    "    option_characteristics=pd.DataFrame((x.split('_') for x in option['symbol']), columns=['ticker','expiry_date','strike_price','option_type'])\n",
    "    option_characteristics['expiry_date']=pd.to_datetime(option_characteristics['expiry_date'])\n",
    "    option_characteristics['strike_price']= option_characteristics['strike_price'].astype(float)\n",
    "    option=pd.concat([option,option_characteristics],axis=1)\n",
    "\n",
    "    option=option.drop(option[option['option_type']=='P'].index)\n",
    "\n",
    "    option=option.reset_index()\n",
    "\n",
    "    return option\n",
    "\n",
    "\n",
    "'''Computationally cumbersome- Assumptions\n",
    "        1. Selected the strike just greater than spot may not be closest but should be fairly liquid\n",
    "        2. TTE != 0DTE\n",
    "        3. Trading only on option closes\n",
    "'''\n",
    "def convert_option_data(option,new_timeframe):  \n",
    "\n",
    "    option_close= option.pivot(index='start_ts', columns='symbol', values='close')\n",
    "    option_close= option_close.resample(new_timeframe).last()\n",
    "    option_close= strip_extra_trading_hours(option_close)    \n",
    "\n",
    "    # option_volume= option.pivot(index='start_ts', columns='symbol', values='volume')\n",
    "    # option_volume= option_volume.resample(new_timeframe).sum()\n",
    "    # option_volume= strip_extra_trading_hours(option_volume)         \n",
    "\n",
    "    return option_close\n",
    "\n",
    "def precompute_spread(eqt, option_close, option_all):\n",
    "\n",
    "    spread=pd.DataFrame()\n",
    "\n",
    "    option_close=option_close.set_index('start_ts')\n",
    "\n",
    "    for _,rows in eqt.iterrows():\n",
    "        symbol=rows['symbol']\n",
    "        start_ts=rows['start_ts']\n",
    "        spot_price=rows['close']\n",
    "        \n",
    "        valid_expires = option_all[option_all['expiry_date'] > rows['start_ts']]\n",
    "        closest_expires= valid_expires['expiry_date'].unique()[:2]\n",
    "        near_expiry= str(closest_expires[0].date().strftime(\"%Y%m%d\"))\n",
    "        far_expiry= str(closest_expires[1].date().strftime(\"%Y%m%d\"))\n",
    "\n",
    "        otm_strikes= option_all[option_all['strike_price'] >= spot_price]\n",
    "        nearest_atm_strike= int(otm_strikes.iloc[0]['strike_price'])\n",
    "\n",
    "        option1=f\"{symbol}_{near_expiry}_{nearest_atm_strike}_C\"\n",
    "        option2=f\"{symbol}_{far_expiry}_{nearest_atm_strike}_C\"\n",
    "\n",
    "        option1_price= option_close.loc[start_ts,option1]\n",
    "        option2_price= option_close.loc[start_ts,option2]\n",
    "\n",
    "        # print(start_ts, option1, option1_price, option2, option2_price)\n",
    "\n",
    "        tte1=(closest_expires[0]- start_ts)/pd.Timedelta(days=365)\n",
    "        tte2=(closest_expires[1]- start_ts)/pd.Timedelta(days=365)\n",
    "\n",
    "        temp={}\n",
    "        temp['start_ts']= start_ts\n",
    "        temp['price']= option2_price -option1_price\n",
    "        temp['iv']= calculate_iv(option2_price, spot_price, nearest_atm_strike, tte2 ,risk_free_rate, 'C')- calculate_iv(option1_price, spot_price, nearest_atm_strike, tte1 ,risk_free_rate, 'C')\n",
    "\n",
    "        spread=pd.concat([spread, pd.DataFrame([temp])])\n",
    "\n",
    "    return spread\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "def generate_features(data, window=60):\n",
    "\n",
    "    # IV and price spreads\n",
    "    data['IV_Spread'] = data['IV_Exp1'] - data['IV_Exp2']\n",
    "    data['Price_Spread'] = data['Price_Exp1'] - data['Price_Exp2']\n",
    "    \n",
    "    # Rolling statistics\n",
    "    data['IV_Mean'] = data['IV_Spread'].rolling(window).mean()\n",
    "    data['IV_Std'] = data['IV_Spread'].rolling(window).std()\n",
    "    data['Price_Mean'] = data['Price_Spread'].rolling(window).mean()\n",
    "    data['Price_Std'] = data['Price_Spread'].rolling(window).std()\n",
    "    \n",
    "    # Z-scores\n",
    "    data['IV_Z_Score'] = (data['IV_Spread'] - data['IV_Mean']) / data['IV_Std']\n",
    "    data['Price_Z_Score'] = (data['Price_Spread'] - data['Price_Mean']) / data['Price_Std']\n",
    "    \n",
    "    # Lagged features\n",
    "    for lag in range(1, 4):\n",
    "        data[f'IV_Spread_Lag{lag}'] = data['IV_Spread'].shift(lag)\n",
    "        data[f'Price_Spread_Lag{lag}'] = data['Price_Spread'].shift(lag)\n",
    "        data[f'IV_Z_Score_Lag{lag}'] = data['IV_Z_Score'].shift(lag)\n",
    "    \n",
    "    # Target: Binary classification (Profit/Loss based on future spread return)\n",
    "    data['Target'] = (data['Price_Spread'].shift(-1) - data['Price_Spread']) > 0\n",
    "    data['Target'] = data['Target'].astype(int)\n",
    "    \n",
    "    # print(data.head)\n",
    "    return data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Equity trading hours from 4am to 8pm'''\n",
    "eqt_path = 'CBOE Data/testeqt.csv'\n",
    "eqt = load_data(eqt_path)\n",
    "\n",
    "eqt_data = convert_eqt_data(eqt,timeframe)\n",
    "print(eqt_data.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Options trading hours from 9.30am to 4pm = 14 Trading sessions'''\n",
    "option_path = 'CBOE Data/testopt.csv'\n",
    "option = load_data(option_path)\n",
    "\n",
    "option_all= data_filtering(option)\n",
    "\n",
    "#Convert to 30min Timeframe\n",
    "option_close = convert_option_data(option,timeframe)\n",
    "print(option_close.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             start_ts  price        iv\n",
      "0 2023-01-03 09:30:00   1.46 -0.118540\n",
      "0 2023-01-03 10:00:00   1.35 -0.143631\n",
      "0 2023-01-03 10:30:00   1.45 -0.118076\n",
      "0 2023-01-03 11:00:00   1.45 -0.114945\n",
      "0 2023-01-03 11:30:00   1.49 -0.117617\n",
      "0 2023-01-03 12:00:00   1.47 -0.117927\n",
      "0 2023-01-03 12:30:00   1.50 -0.115089\n",
      "0 2023-01-03 13:00:00   1.50 -0.122156\n",
      "0 2023-01-03 13:30:00   1.49 -0.120786\n",
      "0 2023-01-03 14:00:00   1.44 -0.131022\n",
      "0 2023-01-03 14:30:00   1.47 -0.129440\n",
      "0 2023-01-03 15:00:00   1.43 -0.128920\n",
      "0 2023-01-03 15:30:00   1.50 -0.114424\n",
      "0 2023-01-04 09:30:00   1.50 -0.160269\n",
      "0 2023-01-04 10:00:00   1.46 -0.168187\n",
      "0 2023-01-04 10:30:00   1.39 -0.165763\n",
      "0 2023-01-04 11:00:00   1.47 -0.149953\n",
      "0 2023-01-04 11:30:00   1.54 -0.139541\n",
      "0 2023-01-04 12:00:00   1.47 -0.141188\n",
      "0 2023-01-04 12:30:00   1.50 -0.153102\n",
      "0 2023-01-04 13:00:00   1.45 -0.161549\n",
      "0 2023-01-04 13:30:00   1.53 -0.138948\n",
      "0 2023-01-04 14:00:00   1.61 -0.147354\n",
      "0 2023-01-04 14:30:00   1.50 -0.151272\n",
      "0 2023-01-04 15:00:00   1.53 -0.164843\n",
      "0 2023-01-04 15:30:00   1.58 -0.145586\n"
     ]
    }
   ],
   "source": [
    "spread= precompute_spread(eqt_data,option_close,option_all)\n",
    "print(spread)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
